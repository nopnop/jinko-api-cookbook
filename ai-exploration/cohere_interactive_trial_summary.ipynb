{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jinko specifics imports & initialization\n",
    "# Please fold this section and do not change\n",
    "import jinko_helpers as jinko\n",
    "\n",
    "# Connect to Jinko (see README.md for more options)\n",
    "jinko.initialize()\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohere specific imports\n",
    "import cohere\n",
    "import os\n",
    "\n",
    "# Connect to cohere\n",
    "cohere_api_key = os.environ.get(\"COHERE_API_KEY\")\n",
    "co = cohere.ClientV2(cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cookbook specifics imports\n",
    "import utils\n",
    "\n",
    "# Cookbook specifics constants:\n",
    "# put here the constants that are specific to your cookbook like\n",
    "# the reference to the Jinko items, the name of the model, etc.\n",
    "\n",
    "trial_viz_sid = \"tv-U0lH-nna1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Creation \n",
    "\n",
    "We'll use this resource:\n",
    " - Trial Viz : https://jinko.ai/tv-U0lH-nna1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_summary = utils.get_trial_summary(trial_viz_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom system message\n",
    "system_message = \"\"\"## Task and Context\n",
    "You will be provided the summary of an in silico clinical trial. This will be the reference document.\n",
    "The user will then ask you questions about this doc and may ask you to modify some fields. \n",
    "If the user asks you to modify one field you should update the reference document in your knowledge base.\"\"\"\n",
    "\n",
    "trial_summary_message = \"here is the summary: \" + str(trial_summary)\n",
    "\n",
    "# Add the user message\n",
    "user_message_english_summary = \"Can you provide a bullet point summary of my trial?\"\n",
    "\n",
    "# Add the messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": trial_summary_message},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I correctly loaded your in silico trial data, how can I help?\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": user_message_english_summary},\n",
    "]\n",
    "\n",
    "# Generate the response\n",
    "response = co.chat_stream(model=\"command-r-plus-08-2024\", messages=messages)\n",
    "\n",
    "# Stream the response and save it in a list\n",
    "final_response = utils.print_and_save_stream(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the previous response\n",
    "messages.append({\"role\": \"assistant\", \"content\": final_response})\n",
    "\n",
    "# Add the user message\n",
    "message = \"Can you provide a bullet point summary of my trial but in japanese?\"\n",
    "\n",
    "# Append the user message\n",
    "messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "# Generate the response with the current chat history as the context\n",
    "response = co.chat_stream(model=\"command-r-plus-08-2024\", messages=messages)\n",
    "\n",
    "# Stream the response and save it in a list\n",
    "final_response = utils.print_and_save_stream(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the previous response\n",
    "messages.append({\"role\": \"assistant\", \"content\": final_response})\n",
    "\n",
    "# Add the user message\n",
    "message = \"How many arms are there in the study?\"\n",
    "\n",
    "# Append the user message\n",
    "messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "# Generate the response with the current chat history as the context\n",
    "response = co.chat_stream(model=\"command-r-plus-08-2024\", messages=messages)\n",
    "\n",
    "# Stream the response and save it in a list\n",
    "final_response = utils.print_and_save_stream(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the previous response\n",
    "messages.append({\"role\": \"assistant\", \"content\": final_response})\n",
    "\n",
    "# Add the user message\n",
    "message = \"For the protocols with a dose of 30, can you change it to 50 and return a description of the updated arms (in english)?\"\n",
    "\n",
    "# Append the user message\n",
    "messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "# Generate the response with the current chat history as the context\n",
    "response = co.chat_stream(model=\"command-r-plus-08-2024\", messages=messages)\n",
    "\n",
    "# Stream the response and save it in a list\n",
    "final_response = utils.print_and_save_stream(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the previous response\n",
    "messages.append({\"role\": \"assistant\", \"content\": final_response})\n",
    "\n",
    "# Add the user message\n",
    "message = \"Can you provide the updated json reference document?\"\n",
    "\n",
    "# Append the user message\n",
    "messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "# Generate the response with the current chat history as the context\n",
    "response = co.chat_stream(model=\"command-r-plus-08-2024\", messages=messages)\n",
    "\n",
    "# Stream the response and save it in a list\n",
    "final_response = utils.print_and_save_stream(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinko-api-doc-qhtqbAjx-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
