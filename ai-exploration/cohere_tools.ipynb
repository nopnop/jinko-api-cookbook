{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jinko specifics imports & initialization\n",
    "# Please fold this section and do not change\n",
    "import jinko_helpers as jinko\n",
    "\n",
    "# Connect to Jinko (see README.md for more options)\n",
    "jinko.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohere specific imports\n",
    "import cohere\n",
    "import os\n",
    "\n",
    "# Connect to cohere\n",
    "cohere_api_key = os.environ.get(\"COHERE_API_KEY\")\n",
    "co = cohere.ClientV2(cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cookbook specifics imports\n",
    "import json\n",
    "\n",
    "# Cookbook specifics constants:\n",
    "# put here the constants that are specific to your cookbook like\n",
    "# the reference to the Jinko items, the name of the model, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Tool\" aka function call use case\n",
    "\n",
    "In this use case, we try to retrieve the coreItemId given the short id of the PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "The developer provides the get_core_item_id fuction to the model using the tools parameter.\n",
    "\n",
    "Observe that, for each tool, the developer describes the tool name, description, and inputs. Each input can have a type and can be marked as required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def wrap_get_core_item_id(shortId: str) -> dict:\n",
    "    return jinko.get_core_item_id(shortId)[\"id\"]\n",
    "\n",
    "\n",
    "functions_map = {\n",
    "    \"wrap_get_core_item_id\": wrap_get_core_item_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definitions\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"wrap_get_core_item_id\",\n",
    "            \"description\": \"Retrieves the core item id of a project item from its short id.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"shortId\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The short id of the project item.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"shortId\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "## Task & Context\n",
    "You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n",
    "\n",
    "## Style Guide\n",
    "Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n",
    "\"\"\"\n",
    "\n",
    "# user request\n",
    "\n",
    "pi_short_id = (\n",
    "    \"cm-sIDm-CniF\"  # this is a real short id of a cm already uploaded to jinko, in the api cookbooks project\n",
    ")\n",
    "user_message = \"Please give me the core item id of PI with sid : \" + str(pi_short_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "The model’s response contains the tool plan, a list of appropriate tools to call in order to answer the user’s question, as well as the appropriate inputs for each tool call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(\"The model recommends doing the following tool calls:\\n\")\n",
    "print(\"Tool plan:\")\n",
    "print(response.message.tool_plan, \"\\n\")\n",
    "print(\"Tool calls:\")\n",
    "for tc in response.message.tool_calls:\n",
    "    print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "\n",
    "# append the chat history\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"tool_calls\": response.message.tool_calls,\n",
    "        \"tool_plan\": response.message.tool_plan,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Now, the developer will query the appropriate tools and receive a tool result in return.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the tool calls generated by the model\n",
    "for tc in response.message.tool_calls:\n",
    "    # here is where you would call the tool recommended by the model, using the parameters recommended by the model\n",
    "    tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "    # store the output in a list\n",
    "    tool_content = [{\"type\": \"document\", \"document\": {\"data\": tool_result}}]\n",
    "    # Optional: add an \"id\" field in the \"document\" object, otherwise IDs are auto-generated\n",
    "    # append the chat history\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": tool_content})\n",
    "\n",
    "    print(\"Tool results that will be fed back to the model in step 4:\")\n",
    "    for result in tool_content:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "Call the chat endpoint again with the tool results for the model to generate the response with citations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = co.chat(model=\"command-r-plus-08-2024\", messages=messages, tools=tools)\n",
    "print(\"Final answer:\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One function for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def wrap_get_core_item_id(shortId: str) -> dict:\n",
    "    return jinko.get_core_item_id(shortId)[\"id\"]\n",
    "\n",
    "\n",
    "functions_map = {\n",
    "    \"wrap_get_core_item_id\": wrap_get_core_item_id,\n",
    "}\n",
    "\n",
    "# Tool definitions\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"wrap_get_core_item_id\",\n",
    "            \"description\": \"Retrieves the core item id of a project item from its short id.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"shortId\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The short id of the project item.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"shortId\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def run_chatbot(user_message):\n",
    "\n",
    "    # Messages building\n",
    "    system_message = \"\"\"\n",
    "    ## Task & Context\n",
    "    You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n",
    "\n",
    "    ## Style Guide\n",
    "    Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    print(response.message.tool_plan, \"\\n\")\n",
    "\n",
    "    # append the chat history\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"tool_calls\": response.message.tool_calls,\n",
    "            \"tool_plan\": response.message.tool_plan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Iterate over the tool calls generated by the model\n",
    "    for tc in response.message.tool_calls:\n",
    "        # here is where you would call the tool recommended by the model, using the parameters recommended by the model\n",
    "        tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "        # store the output in a list\n",
    "        tool_content = [{\"type\": \"document\", \"document\": {\"data\": tool_result}}]\n",
    "        # Optional: add an \"id\" field in the \"document\" object, otherwise IDs are auto-generated\n",
    "        # append the chat history\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": tool_content})\n",
    "\n",
    "        response = co.chat(model=\"command-r-plus-08-2024\", messages=messages, tools=tools)\n",
    "        print(response.message.content[0].text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Please give me the core item id of PI with sid : cm-sIDm-CniF\"\n",
    "\n",
    "run_chatbot(user_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinko-api-doc-qhtqbAjx-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
