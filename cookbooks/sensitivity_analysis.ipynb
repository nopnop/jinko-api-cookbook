{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3242c62",
   "metadata": {},
   "source": [
    "# Sensitivity analysis on trial results (responder identification)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this cookbook is to demonstrate how one can perform a sensitivy analysis on simulation outputs, in order to identify the patient descriptors that have the highest impact on a given response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f9cb-d8c3-42c5-839e-18299ac270b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Jinko specifics imports & initialization\n",
    "# Please fold this section and do not change\n",
    "import jinko_helpers as jinko\n",
    "\n",
    "# Connect to Jinko (see README.md for more options)\n",
    "jinko.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cd001-eb69-4f91-a7f8-5a4af8229589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cookbook specific imports\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LassoCV, lasso_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import zipfile\n",
    "\n",
    "# Cookbook specific constants:\n",
    "# Put here the constants that are specific to your cookbook like\n",
    "# the reference to the Jinko items, the name of the model, etc.\n",
    "\n",
    "# @param {\"name\":\"trialId\", \"type\": \"string\"}\n",
    "# The trial's short id can be retrieved in the url, pattern is `https://jinko.ai/<trail_sid>`\n",
    "trial_sid = \"tr-9Bid-BL1I\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32e10a",
   "metadata": {},
   "source": [
    "# Step 1: Loading the trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca2279",
   "metadata": {},
   "source": [
    "### Get the latest completed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8d40f-f6d1-4250-8a0d-b1c4e07c8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert short id to core item id\n",
    "trial_core_item_id = jinko.getCoreItemId(trial_sid, 1)\n",
    "\n",
    "# List all trial versions\n",
    "# https://doc.jinko.ai/api/#/paths/core-v2-trial_manager-trial-trialId--status/get\n",
    "response = jinko.makeRequest(\n",
    "    f'/core/v2/trial_manager/trial/{trial_core_item_id[\"id\"]}/status'\n",
    ")\n",
    "versions = response.json()\n",
    "\n",
    "# Get the latest completed version\n",
    "try:\n",
    "    latest_completed_version = next(\n",
    "        (item for item in versions if item[\"status\"] == \"completed\"), None\n",
    "    )\n",
    "    if latest_completed_version is None:\n",
    "        raise Exception(\"No completed trial version found\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Successfully fetched this simulation:\\n\",\n",
    "            json.dumps(latest_completed_version, indent=1),\n",
    "        )\n",
    "        simulation_id = latest_completed_version[\"simulationId\"]\n",
    "        trial_core_item_id = simulation_id[\"coreItemId\"]\n",
    "        trial_snapshot_id = simulation_id[\"snapshotId\"]\n",
    "except Exception as e:\n",
    "    print(f\"Error processing trial versions: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b13c12",
   "metadata": {},
   "source": [
    "# Step 2 : Getting and post processing the trial results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eaa7f2",
   "metadata": {},
   "source": [
    "### Displaying a summary of imported simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcfb73-d8d4-418d-89af-1f65b05e23a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://doc.jinko.ai/api/#/paths/core-v2-trial_manager-trial-trialId--snapshots--trialIdSnapshot--results_summary/get\n",
    "response = jinko.makeRequest(\n",
    "    f\"/core/v2/trial_manager/trial/{trial_core_item_id}/snapshots/{trial_snapshot_id}/results_summary\",\n",
    "    method=\"GET\",\n",
    ")\n",
    "response_summary = json.loads(response.content)\n",
    "\n",
    "# Print a summary of the results content\n",
    "print(\"Keys in the results summary:\\n\", list(response_summary.keys()), \"\\n\")\n",
    "print(\"Available patients:\\n\", response_summary[\"patients\"], \"\\n\")\n",
    "print(\"Available arms:\\n\", response_summary[\"arms\"], \"\\n\")\n",
    "print(\n",
    "    \"Available scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"scalars\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"Available cross-arm scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"scalarsCrossArm\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"Available categorical scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"categoricals\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"Available cross-arm categorical scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"categoricalsCrossArm\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "\n",
    "# Store the list of scenario descriptors fetch them\n",
    "scenario_descriptors = [\n",
    "    scalar[\"id\"]\n",
    "    for scalar in (response_summary[\"scalars\"] + response_summary[\"categoricals\"])\n",
    "    if \"ScenarioOverride\" in scalar[\"type\"][\"labels\"]\n",
    "]\n",
    "print(\"List of scenario overrides:\\n\", scenario_descriptors, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a4ddf",
   "metadata": {},
   "source": [
    "### Retrieving scalar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b60f7-e004-40a5-867e-bdacfb8d4f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://doc.jinko.ai/api/#/paths/core-v2-result_manager-scalars_summary/post\n",
    "response = jinko.makeRequest(\n",
    "    path=\"/core/v2/result_manager/scalars_summary\",\n",
    "    method=\"POST\",\n",
    "    json={\n",
    "        \"select\": [\n",
    "            \"Blood.Drug.max\",\n",
    "            \"bloodFlowRate.tmin\",\n",
    "            \"initialCountCancerCells.tmin\",\n",
    "            \"initialTumorBurden.tmin\",\n",
    "            \"kccCancerCell.tmin\",\n",
    "            \"lymphaticFlowRate.tmin\",\n",
    "            \"lymphDrainingRate.tmin\",\n",
    "            \"tumorBurdenChangeFromBaseline.tend\",\n",
    "            \"Tumor.CancerCell.tmin\",\n",
    "            \"vmaxCancerCellDeath.tmin\",\n",
    "        ],\n",
    "        \"trialId\": latest_completed_version[\"simulationId\"],\n",
    "    },\n",
    ")\n",
    "archive = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "filename = archive.namelist()[0]\n",
    "\n",
    "csv_scalars = archive.read(filename).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205c197-3d19-4eb9-83c3-eb20d35f7ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading scalars into a dataframe\n",
    "df_scalars = pd.read_csv(io.StringIO(csv_scalars))\n",
    "print(\"Raw scalar data (first rows):\\n\")\n",
    "display(df_scalars.head())\n",
    "print(\"\\nNumber of patients in the original table:\", len(df_scalars))\n",
    "\n",
    "# Filtering patients (keeping only cross arm baseline values and IV 10mg dose)\n",
    "df_scalars = df_scalars[df_scalars[\"armId\"].isin([\"crossArms\", \"iv-1-10\"])]\n",
    "print(f\"\\nNumber of patients in the table after filtering:\", len(df_scalars))\n",
    "\n",
    "# Pivoting to a wide format\n",
    "df_scalars = df_scalars.drop(\"armId\", axis=1)\n",
    "df_scalars = df_scalars.pivot(index=\"patientId\", columns=\"scalarId\", values=\"value\")\n",
    "\n",
    "# Checking the result\n",
    "print(\"\\nPivoted scalar table (first rows):\")\n",
    "display(df_scalars.head())\n",
    "\n",
    "# Creating a column for the response to the treatment (binary outcome)\n",
    "df_scalars[\"responder\"] = df_scalars[\"tumorBurdenChangeFromBaseline.tend\"].apply(\n",
    "    lambda x: x <= -95\n",
    ")\n",
    "print(\"\\nResponse variable (first rows):\")\n",
    "display(df_scalars[[\"tumorBurdenChangeFromBaseline.tend\", \"responder\"]].head())\n",
    "\n",
    "# Checking if there are NaN values in the table\n",
    "nan_rows = df_scalars.isna().any(axis=1)\n",
    "id_to_remove = nan_rows[nan_rows].index.values\n",
    "print(\n",
    "    \"\\n\",\n",
    "    len(id_to_remove),\n",
    "    \"patient(s) containing NaN values in the table will be removed:\",\n",
    ")\n",
    "display(df_scalars[df_scalars.index.isin(id_to_remove)])\n",
    "\n",
    "# Removing corresponding row(s)\n",
    "df_scalars = df_scalars.drop(index=id_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23849cc",
   "metadata": {},
   "source": [
    "# Step 3 : Defining explanatory and response variables\n",
    "## 3.1 : Selecting variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36d88a-d03c-4c9c-9332-862940b6ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"Blood.Drug.max\",\n",
    "    \"bloodFlowRate.tmin\",\n",
    "    \"initialCountCancerCells.tmin\",\n",
    "    \"initialTumorBurden.tmin\",\n",
    "    \"kccCancerCell.tmin\",\n",
    "    \"lymphaticFlowRate.tmin\",\n",
    "    \"lymphDrainingRate.tmin\",\n",
    "    \"Tumor.CancerCell.tmin\",\n",
    "    \"vmaxCancerCellDeath.tmin\",\n",
    "]\n",
    "\n",
    "X = df_scalars[feature_cols]  # Features\n",
    "y_num = df_scalars[\"tumorBurdenChangeFromBaseline.tend\"]  # Continuous target variable\n",
    "y_bin = df_scalars[\"responder\"]  # Binary target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb36eaf1-ff17-4155-9380-482d6dd9839c",
   "metadata": {},
   "source": [
    "## 3.2 : Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc403c-6e42-455e-93d4-63bb69688b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of samples in each class\n",
    "counts = df_scalars[\"responder\"].value_counts()\n",
    "print(\"Number of samples in each class:\")\n",
    "for label, count in counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_num_train, y_num_test, y_bin_train, y_bin_test = train_test_split(\n",
    "    X, y_num, y_bin, test_size=0.3, random_state=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4df30-41fe-49df-aa78-38f6434116a7",
   "metadata": {},
   "source": [
    "## Step 4 : Applying feature selection approaches\n",
    "### Penalized regression (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),  # Step 1: Standardize the data\n",
    "        (\"lasso_cv\", LassoCV(cv=5, random_state=0)),  # Step 2: Cross-validated Lasso\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_num_train)\n",
    "\n",
    "# Extract the scaled training data from the pipeline\n",
    "X_train_scaled = pipeline.named_steps[\"scaler\"].transform(X_train)\n",
    "\n",
    "# Searching for the best alpha value\n",
    "best_alpha = pipeline.named_steps[\"lasso_cv\"].alpha_\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Predict using the pipeline\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "\n",
    "# Estimating the paths of coefficients using the same scaling\n",
    "alphas_lasso, coefs, _ = lasso_path(\n",
    "    X_train_scaled, y_num_train, alphas=pipeline.named_steps[\"lasso_cv\"].alphas_\n",
    ")\n",
    "\n",
    "# Initializing figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plotting each coefficient path\n",
    "for i in range(coefs.shape[0]):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=alphas_lasso,\n",
    "            y=coefs[i, :],\n",
    "            mode=\"lines\",\n",
    "            name=X.columns[i],\n",
    "            hoverinfo=\"name+x+y\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Adding a vertical line for the best alpha\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[best_alpha, best_alpha],\n",
    "        y=[coefs.min(), coefs.max()],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "        name=\"Best Alpha\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Updating the layout\n",
    "fig.update_layout(\n",
    "    title=\"Lasso coefficients as a function of alpha\",\n",
    "    xaxis_title=\"Alpha\",\n",
    "    yaxis_title=\"Coefficients\",\n",
    "    xaxis=dict(type=\"log\", autorange=\"reversed\"),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Fitting the lasso model with the best alpha\n",
    "lasso_final = Lasso(alpha=best_alpha).fit(X_train_scaled, y_num_train)\n",
    "\n",
    "# Extracting the coefficients\n",
    "lasso_coefficients = pd.Series(lasso_final.coef_, index=X_train.columns)\n",
    "print(\"Lasso coefficients:\")\n",
    "display(lasso_coefficients)\n",
    "\n",
    "# Filtering features with non-zero coefficients (i.e., selected features)\n",
    "selected_features = lasso_coefficients[lasso_coefficients != 0]\n",
    "print(\"\\nSelected features only:\")\n",
    "display(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6a6ac-1e2f-4df2-9f60-cbfd068734c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5463607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),  # Step 1: Standardize the data\n",
    "        (\n",
    "            \"rf\",\n",
    "            RandomForestRegressor(n_estimators=100, random_state=0),\n",
    "        ),  # Step 2: Train Random Forest\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_num_train)\n",
    "\n",
    "# Percentage of explained variance (R^2)\n",
    "explained_variance = pipeline.score(X_train, y_num_train) * 100\n",
    "print(f\"Percentage of explained variance (R^2): {explained_variance:.2f}%\")\n",
    "\n",
    "# Extracting feature importances\n",
    "rf_importances = pipeline.named_steps[\"rf\"].feature_importances_\n",
    "\n",
    "# Storing feature importances in a DataFrame\n",
    "feature_importances = pd.DataFrame(\n",
    "    {\"Features\": X_train.columns, \"Importance\": rf_importances}\n",
    ")\n",
    "\n",
    "# Sort by importance\n",
    "feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=True)\n",
    "\n",
    "# Display the feature importances using Plotly\n",
    "fig = px.bar(\n",
    "    feature_importances,\n",
    "    x=\"Importance\",\n",
    "    y=\"Features\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Explanatory variables ranked by importance\",\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
