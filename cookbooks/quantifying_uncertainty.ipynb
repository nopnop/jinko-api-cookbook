{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54b1324-9c03-46f7-b920-5ff92c95123e",
   "metadata": {},
   "source": [
    "# Quantifying uncertainty in simulation results\n",
    "## Introduction\n",
    "\n",
    "The purpose of this cookbook is to demonstrate how one can compute and plot the 95% percentile prediction interval (PPI) of the mean for multiple time series at once. \n",
    "\n",
    "To compute a PPI for a given summary metric (e.g.: the mean), a given number of randomly samples of size n are drawn from a larger population. The metric of interest is computed for each sample, therefore allowing to estimate the empirical distribution of the latter. The 2.5% and 97.5% percentiles are then estimated. \n",
    "\n",
    "The PPI is a relevant metric to assess the degree of uncertainty embedded in the model and eventually to compare it to the uncertainty observed in a real-life setting. Indeed, standard confidence intervals are not well suited for the in silico context as they tend to get very narrow as the Virtual Population (VP) size increases. On the other hand, PPI allows to define a sample size (in the case where the VP is much larger than a real-life clinical trial, one can use the same sample size as the one used for real life observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138dd704-b7d0-42f4-867c-ea4f80c1adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jinko specifics imports & initialization\n",
    "# Please fold this section and do not edit it\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../lib\")\n",
    "import jinko_helpers as jinko\n",
    "\n",
    "# Connect to Jinko (see README.md for more options)\n",
    "\n",
    "jinko.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9944f60-72f7-40ae-b85a-af6ebbdcae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cookbook specifics imports\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# Cookbook specifics constants:\n",
    "# put here the constants that are specific to your cookbook like\n",
    "# the reference to the Jinko items, the name of the model, etc.\n",
    "\n",
    "# @param {\"name\":\"trialId\", \"type\": \"string\"}\n",
    "# trial short id can be retrieved in the url, pattern is `https://jinko.ai/<trail_sid>`\n",
    "trial_sid = \"tr-9Bid-BL1I\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6829c0-29c3-4ac7-a0ec-68f5d542c48c",
   "metadata": {},
   "source": [
    "## Step 1: Loading the trial and getting the last completed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f24608-a47d-4339-b683-25e3a041f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert short id to core item id\n",
    "trial_core_item_id = jinko.getCoreItemId(trial_sid, 1)\n",
    "\n",
    "# List all trial versions\n",
    "# https://doc.jinko.ai/api/#/paths/core-v2-trial_manager-trial-trialId--status/get\n",
    "response = jinko.makeRequest(\n",
    "    f'/core/v2/trial_manager/trial/{trial_core_item_id[\"id\"]}/status'\n",
    ")\n",
    "versions = response.json()\n",
    "\n",
    "# Get the latest completed version\n",
    "try:\n",
    "    latest_completed_version = next(\n",
    "        (item for item in versions if item[\"status\"] == \"completed\"), None\n",
    "    )\n",
    "    if latest_completed_version is None:\n",
    "        raise Exception(\"No completed trial version found\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Successfully fetched this simulation:\\n\",\n",
    "            json.dumps(latest_completed_version, indent=1),\n",
    "        )\n",
    "        simulation_id = latest_completed_version[\"simulationId\"]\n",
    "        trial_core_item_id = simulation_id[\"coreItemId\"]\n",
    "        trial_snapshot_id = simulation_id[\"snapshotId\"]\n",
    "except Exception as e:\n",
    "    print(f\"Error processing trial versions: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99d77a-e6aa-4f7f-97e7-287759b73249",
   "metadata": {},
   "source": [
    "## Step 2: Displaying a summary of the data content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fa188-1157-41a5-b3a6-0437ba55d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://doc.jinko.ai/api/#/paths/core-v2-trial_manager-trial-trialId--snapshots--trialIdSnapshot--results_summary/get\n",
    "response = jinko.makeRequest(\n",
    "    f\"/core/v2/trial_manager/trial/{trial_core_item_id}/snapshots/{trial_snapshot_id}/results_summary\",\n",
    "    method=\"GET\",\n",
    ")\n",
    "response_summary = json.loads(response.content)\n",
    "\n",
    "# Print a summary of the results content\n",
    "print(\"Keys in the results summary:\\n\", list(response_summary.keys()), \"\\n\")\n",
    "print(\"Available patients:\\n\", response_summary[\"patients\"], \"\\n\")\n",
    "print(\"Available arms:\\n\", response_summary[\"arms\"], \"\\n\")\n",
    "print(\n",
    "    \"Available scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"scalars\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"Available cross-arm scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"scalarsCrossArm\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"Available categorical scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"categoricals\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"Available cross-arm categorical scalars:\\n\",\n",
    "    [scalar[\"id\"] for scalar in response_summary[\"categoricalsCrossArm\"]],\n",
    "    \"\\n\",\n",
    ")\n",
    "\n",
    "# Store the list of scenario descriptors fetch them\n",
    "scenario_descriptors = [\n",
    "    scalar[\"id\"]\n",
    "    for scalar in (response_summary[\"scalars\"] + response_summary[\"categoricals\"])\n",
    "    if \"ScenarioOverride\" in scalar[\"type\"][\"labels\"]\n",
    "]\n",
    "print(\"List of scenario overrides:\\n\", scenario_descriptors, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ccf1f1-476f-4f27-9089-47c00d8deacd",
   "metadata": {},
   "source": [
    "## Step 3: Retrieving time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b8ac0-11d5-461e-a0bf-43d1d2feb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the time series to retrieve\n",
    "time_series_ids = [\"Blood.Drug\", \"Tumor.CancerCell\"]\n",
    "\n",
    "try:\n",
    "    print(\"Retrieving time series data...\")\n",
    "    response = jinko.makeRequest(\n",
    "        \"/core/v2/result_manager/timeseries_summary\",\n",
    "        method=\"POST\",\n",
    "        json={\n",
    "            \"select\": time_series_ids,\n",
    "            \"trialId\": latest_completed_version[\"simulationId\"],\n",
    "        },\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Time series data retrieved successfully.\")\n",
    "        archive = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        filename = archive.namelist()[0]\n",
    "        print(f\"Extracted time series file: {filename}\")\n",
    "        csv_time_series = archive.read(filename).decode(\"utf-8\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to retrieve time series data: {response.status_code} - {response.reason}\"\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "except Exception as e:\n",
    "    print(f\"Error during time series retrieval or processing: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2d09b-f452-4a63-9e5e-25fa8fc268da",
   "metadata": {},
   "source": [
    "## Step 4: Post-processing the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172476bc-21e6-4431-9c01-1a2a7c67cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading timeseries into a dataframe\n",
    "df_time_series = pd.read_csv(io.StringIO(csv_time_series))\n",
    "print(\"Raw timeseries data (first rows): \\n\")\n",
    "display(df_time_series.head())\n",
    "\n",
    "# Count the number of observations per time point\n",
    "counts = df_time_series[\"Time\"].value_counts()\n",
    "\n",
    "# Check if all time points have the same number of observations\n",
    "all_equal = counts.nunique() == 1\n",
    "\n",
    "if all_equal:\n",
    "    print(\"All time points have the same number of observations.\")\n",
    "else:\n",
    "    print(f\"Time points have varying numbers of observations:\\n{counts.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d92f1-fbf5-45ba-bc3b-8bb6ab1bd9d2",
   "metadata": {},
   "source": [
    "## Step 5: Computing mean value by time point, for each arm and each descriptor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae04da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means_grouped = (\n",
    "    df_time_series.groupby([\"Arm\", \"Descriptor\", \"Time\"])[\"Value\"].mean().reset_index()\n",
    ")\n",
    "df_means_grouped = pd.DataFrame(df_means_grouped)\n",
    "display(df_means_grouped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b0d28-ffae-4d1a-8705-0e52ff7e4654",
   "metadata": {},
   "source": [
    "## Step 6: Computing the 95% percentiles (basic version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549cca3-596f-4e47-87af-b82314d7ea14",
   "metadata": {},
   "source": [
    "### Defining a function to compute the 2.5% and 97.5% percentiles and another to perform the bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2521e8-9f01-4ec4-9508-dbb288e47acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentiles(x):\n",
    "    return x.quantile([0.025, 0.975]).values\n",
    "\n",
    "\n",
    "def generate_subsample_means(group, num_subsamples, sample_size):\n",
    "    subsample_means = []\n",
    "    for _ in range(num_subsamples):\n",
    "        subsample = group[\"Value\"].sample(n=sample_size, replace=False)\n",
    "        subsample_means.append(subsample.mean())\n",
    "    return subsample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d33be-0039-493c-a15f-b3453d65ad5b",
   "metadata": {},
   "source": [
    "### Applying both function to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7c0de-5923-4f7c-bbfd-61ae0e1ffa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of subsamples and sample size\n",
    "num_subsamples = 50\n",
    "sample_size = 50\n",
    "\n",
    "# Grouping by descriptor, arm and time and applying the function\n",
    "df_subsample_means = (\n",
    "    df_time_series.groupby([\"Descriptor\", \"Arm\", \"Time\"])\n",
    "    .apply(\n",
    "        lambda group: generate_subsample_means(\n",
    "            group[[\"Value\"]], num_subsamples, sample_size\n",
    "        ),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Exploding the list of means into separate rows\n",
    "df_subsample_means = df_subsample_means.explode(0).reset_index(drop=True)\n",
    "df_subsample_means.columns = [\"Descriptor\", \"Arm\", \"Time\", \"Subsample_Mean\"]\n",
    "\n",
    "print(df_subsample_means.head())\n",
    "\n",
    "# Computing percentiles\n",
    "df_percentiles_grouped = (\n",
    "    df_subsample_means.groupby([\"Arm\", \"Descriptor\", \"Time\"])[\"Subsample_Mean\"]\n",
    "    .apply(percentiles)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Splitting the newly generated column into two separate ones\n",
    "df_percentiles_grouped[[\"LoBound\", \"HiBound\"]] = pd.DataFrame(\n",
    "    df_percentiles_grouped[\"Subsample_Mean\"].tolist(),\n",
    "    index=df_percentiles_grouped.index,\n",
    ")\n",
    "df_percentiles_grouped = df_percentiles_grouped.drop(columns=[\"Subsample_Mean\"])\n",
    "display(df_percentiles_grouped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1172e1c2-4c9b-4f19-81f0-e0b7c92e5ccf",
   "metadata": {},
   "source": [
    "## Step 7: Merging the two data-frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc41f2-fc6a-48f8-a238-0dc1e015d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two data frames together\n",
    "df_ppi = pd.merge(\n",
    "    df_means_grouped, df_percentiles_grouped, on=[\"Arm\", \"Descriptor\", \"Time\"]\n",
    ")\n",
    "display(df_ppi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91983fa-1eb6-4ca6-a06a-3ba17cd600a8",
   "metadata": {},
   "source": [
    "# Step 8: Plotting the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764188f3-023e-4729-b331-bb137b498e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating subplots\n",
    "unique_variables = df_ppi[\"Descriptor\"].unique()\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=len(unique_variables),\n",
    "    shared_yaxes=False,\n",
    "    subplot_titles=unique_variables,\n",
    ")\n",
    "\n",
    "## Defining colors for different arms\n",
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "## Creating a dictionary to map each arm to a color\n",
    "unique_arm = df_ppi[\"Arm\"].unique()\n",
    "color_map = {\n",
    "    category: palette[i % len(palette)] for i, category in enumerate(unique_arm)\n",
    "}\n",
    "\n",
    "\n",
    "## Looping through each descriptor and adding traces for mean, lower bound, and upper bound stratified by arm\n",
    "for i, group in enumerate(unique_variables):\n",
    "    group_df = df_ppi[df_ppi[\"Descriptor\"] == group]\n",
    "\n",
    "    for arm in unique_arm:\n",
    "        subset = group_df[group_df[\"Arm\"] == arm]\n",
    "\n",
    "        # Add the mean line (plain line)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=subset[\"Time\"],\n",
    "                y=subset[\"Value\"],\n",
    "                mode=\"lines\",\n",
    "                name=f\"{group} {arm} Mean\",\n",
    "                line=dict(color=color_map[arm]),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "        # Add the lower bound line (dotted line)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=subset[\"Time\"],\n",
    "                y=subset[\"LoBound\"],\n",
    "                mode=\"lines\",\n",
    "                name=f\"{group} {arm} 2.5% PPI \",\n",
    "                line=dict(color=color_map[arm], dash=\"dot\"),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "        # Add the upper bound line (dotted line)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=subset[\"Time\"],\n",
    "                y=subset[\"HiBound\"],\n",
    "                mode=\"lines\",\n",
    "                name=f\"{group} {arm} 97.5% PPI\",\n",
    "                line=dict(color=color_map[arm], dash=\"dot\"),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "## Updating the layout\n",
    "fig.update_layout(\n",
    "    title=\"Mean and Bootstrapped 95% Prediction Interval Stratified by Variable and Arm\",\n",
    "    xaxis_title=\"X-axis\",\n",
    "    yaxis_title=\"Values\",\n",
    "    legend_title=\"Legend\",\n",
    ")\n",
    "\n",
    "## Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
